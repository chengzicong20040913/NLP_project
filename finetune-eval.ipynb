{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装opencompass：Kaggle上已经为我们准备好了其他常用包，只需安装opencompass用于评测即可。如果不在Kaggle上运行，则还需要安装其他必要包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#! pip install \"opencompass[full]\"#确保3.10版本尝试了一下>3.10,<3.10都不行\n",
    "# !pip install pytorch transformers datasets \"opencompass[full]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指令微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T12:42:50.738461Z",
     "iopub.status.busy": "2024-12-06T12:42:50.738204Z",
     "iopub.status.idle": "2024-12-06T12:42:50.743023Z",
     "shell.execute_reply": "2024-12-06T12:42:50.742025Z",
     "shell.execute_reply.started": "2024-12-06T12:42:50.738434Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The main program for finetuning LLMs with Huggingface Transformers Library.\n",
    "\n",
    "ALL SECTIONS WHERE CODE POSSIBLY NEEDS TO BE FILLED IN ARE MARKED AS TODO.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Dict\n",
    "import sys\n",
    "import torch\n",
    "from transformers import TrainingArguments, HfArgumentParser, Trainer, AutoTokenizer, AutoModelForCausalLM,Qwen2ForCausalLM\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T12:42:54.214990Z",
     "iopub.status.busy": "2024-12-06T12:42:54.214309Z",
     "iopub.status.idle": "2024-12-06T12:42:54.220805Z",
     "shell.execute_reply": "2024-12-06T12:42:54.219860Z",
     "shell.execute_reply.started": "2024-12-06T12:42:54.214952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the arguments required for the main program.\n",
    "# NOTE: You can customize any arguments you need to pass in.\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"Arguments for model\n",
    "    \"\"\"\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The path to the LLM to fine-tune or its name on the Hugging Face Hub.\"\n",
    "        }\n",
    "    )\n",
    "    torch_dtype: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Override the default `torch.dtype` and load the model under this dtype.\"\n",
    "            ),\n",
    "            \"choices\": [\"bfloat16\", \"float16\", \"float32\"],\n",
    "        },\n",
    "    )\n",
    "    # TODO: add your model arguments here\n",
    "    max_length: Optional[int] = field(\n",
    "        default=1024,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum length of the input sequence.\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataArguments:\n",
    "    \"\"\"Arguments for data\n",
    "    \"\"\"\n",
    "    dataset_path: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The path to the fine-tuning dataset or its name on the Hugging Face Hub.\"\n",
    "        }\n",
    "    )\n",
    "    # TODO: add your data arguments here\n",
    "    #调整划分数据集的比例\n",
    "    train_size: Optional[float] = field(\n",
    "        default=0.8,\n",
    "        metadata={\n",
    "            \"help\": \"The proportion of the training dataset.\"\n",
    "        }\n",
    "    )\n",
    "@dataclass\n",
    "class CustomTrainingArguments(TrainingArguments):\n",
    "    train_batch_size:Optional[int] = field(\n",
    "        default=2,\n",
    "        metadata={\n",
    "            \"help\": \"The custom training batch size.\"\n",
    "        }\n",
    "    )\n",
    "    learning_rate: Optional[float] = field(\n",
    "        default=1e-5,\n",
    "        metadata={\n",
    "            \"help\": \"The custom learning rate.\"\n",
    "        }\n",
    "    )\n",
    "    eval_batch_size: Optional[int] = field(\n",
    "        default=2,  # 默认设置为2，视需要调整\n",
    "        metadata={\n",
    "            \"help\": \"The batch size used for evaluation.\"\n",
    "        }\n",
    "    )\n",
    "    max_grad_norm: Optional[float] = field(\n",
    "        default=1.0,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum gradient norm.\"\n",
    "        }\n",
    "    )\n",
    "    logging_steps: Optional[int] = field(\n",
    "        default=20,\n",
    "        metadata={\n",
    "            \"help\": \"Log every X updates steps.\"\n",
    "        }\n",
    "    )\n",
    "    warmup_steps: Optional[int] = field(\n",
    "        default=500,\n",
    "        metadata={\n",
    "            \"help\": \"The number of warmup steps.\"\n",
    "        }\n",
    "    )\n",
    "    save_steps: Optional[int] = field(\n",
    "        default=20000,\n",
    "        metadata={\n",
    "            \"help\": \"Save checkpoint every X updates steps.\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T12:42:58.207418Z",
     "iopub.status.busy": "2024-12-06T12:42:58.207100Z",
     "iopub.status.idle": "2024-12-06T12:42:58.218014Z",
     "shell.execute_reply": "2024-12-06T12:42:58.216987Z",
     "shell.execute_reply.started": "2024-12-06T12:42:58.207391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# The main function\n",
    "# NOTE You can customize some logs to monitor your program.\n",
    "def finetune():\n",
    "    # TODO Step 1: Define an arguments parser and parse the arguments\n",
    "    # NOTE Three parts: model arguments, data arguments, and training arguments\n",
    "    # HINT: Refer to \n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/internal/trainer_utils#transformers.HfArgumentParser\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/trainer#transformers.TrainingArguments\n",
    "    parser = HfArgumentParser((ModelArguments, DataArguments, CustomTrainingArguments))\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "    # TODO Step 2: Load tokenizer and model\n",
    "    # HINT 1: Refer to\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/main_classes/tokenizer#tokenizer\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/model_doc/qwen2\n",
    "    # HINT 2: To save training GPU memory, you need to set the model's parameter precision to half-precision (float16 or bfloat16).\n",
    "    #         You may also check other strategies to save the memory!\n",
    "    #   * https://huggingface.co/docs/transformers/v4.46.3/en/model_doc/llama2#usage-tips\n",
    "    #   * https://huggingface.co/docs/transformers/perf_train_gpu_one\n",
    "    #   * https://www.53ai.com/news/qianyanjishu/2024052494875.html\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        torch_dtype=torch.float16 if model_args.torch_dtype is None else model_args.torch_dtype,\n",
    "    )\n",
    "\n",
    "    # TODO Step 3: Load dataset\n",
    "    # HINT: https://huggingface.co/docs/datasets/v3.1.0/en/package_reference/main_classes#datasets.Dataset\n",
    "    dataset = datasets.load_dataset(data_args.dataset_path)\n",
    "    # HINT: You may need to adjust the dataset to fit the model's input format.\n",
    "\n",
    "    # TODO Step 4: Define the data collator function\n",
    "    # NOTE During training, for each model parameter update, we fetch a batch of data, perform a forward and backward pass,\n",
    "    # and then update the model parameters. The role of the data collator is to process the data (e.g., padding the data within\n",
    "    # a batch to the same length) and format the batch into the input required by the model.\n",
    "    #\n",
    "    # In this assignment, the purpose of the custom data_collator is to process each batch of data from the dataset loaded in\n",
    "    # Step 3 into the format required by the model. This includes tasks such as tokenizing the data, converting each token into \n",
    "    # an ID sequence, applying padding, and preparing labels.\n",
    "    # \n",
    "    # HINT:\n",
    "    #   * Before implementation, you should:\n",
    "    #      1. Clearly understand the format of each sample in the dataset loaded in Step 3.\n",
    "    #      2. Understand the input format required by the model (https://huggingface.co/docs/transformers/model_doc/qwen2#transformers.Qwen2ForCausalLM).\n",
    "    #         Reading its source code also helps!\n",
    "\n",
    "    def data_collator(batch: List[Dict]):\n",
    "        \"\"\"\n",
    "        batch: list of dict, each dict of the list is a sample in the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # 处理每个样本的 'instruction' 和 'input'，将它们拼接起来\n",
    "        texts = [sample['instruction'] +'\\n'+ sample['input'] for sample in batch]\n",
    "        \n",
    "        # 使用 tokenizer 对拼接后的文本进行 tokenization\n",
    "        tokenized_inputs = tokenizer(\n",
    "            texts,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=model_args.max_length,\n",
    "        )\n",
    "\n",
    "        # 使用 tokenizer 对 'output' 进行 tokenization 作为标签\n",
    "        tokenized_labels = tokenizer(\n",
    "            [sample['output'] for sample in batch],  # 这里处理的是每个样本的 'output'\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=model_args.max_length,\n",
    "        )\n",
    "\n",
    "        # 对 causal language modeling，shift labels 向右\n",
    "        input_ids = tokenized_inputs.input_ids\n",
    "        attention_mask = tokenized_inputs.attention_mask\n",
    "        labels = [\n",
    "            [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
    "            for label in tokenized_labels.input_ids\n",
    "        ]\n",
    "        #要转换为torch格式\n",
    "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "        attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        # 返回处理后的 input_ids，attention_mask 和 labels\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels,\n",
    "        }\n",
    "        \n",
    "\n",
    "    # TODO Step 5: Define the Trainer\n",
    "    # HINT: https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "    \n",
    "    train_set=dataset['train']\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_set,\n",
    "        #callbacks=[LossLoggingCallback]  # 传入自定义回调\n",
    "    )\n",
    "\n",
    "    # Step 6: Train!\n",
    "    trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T12:43:09.552702Z",
     "iopub.status.busy": "2024-12-06T12:43:09.552042Z",
     "iopub.status.idle": "2024-12-06T12:46:03.173893Z",
     "shell.execute_reply": "2024-12-06T12:46:03.172922Z",
     "shell.execute_reply.started": "2024-12-06T12:43:09.552665Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='534' max='77640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  534/77640 02:57 < 7:08:48, 3.00 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>15.799200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>15.611700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>15.854300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>15.477400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>14.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>14.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>12.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>10.824300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>9.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>9.560400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>9.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>9.427200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>8.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>8.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>7.995200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>7.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>7.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>7.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>7.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>6.986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>7.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>7.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>6.781100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"#不要并行处理\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2.5-0.5B\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--fp16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 108\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    100\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    101\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m#callbacks=[LossLoggingCallback]  # 传入自定义回调\u001b[39;00m\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Step 6: Train!\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/trainer.py:3688\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3686\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3689\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[1;32m   3690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/accelerate/accelerator.py:2248\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2248\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/NLP/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pass your training arguments.\n",
    "# NOTE [IMPORTANT!!!] DO NOT FORGET TO PASS PROPER ARGUMENTS TO SAVE YOUR CHECKPOINTS!!!\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"#不要并行处理\n",
    "\n",
    "sys.argv = [\n",
    "    \"notebook\", \n",
    "    \"--model_name_or_path\", \"Qwen2.5-0.5B\",\n",
    "    \"--dataset_path\", \"alpaca-cleaned\",\n",
    "    \"--output_dir\", \"outputs\",\n",
    "    \"--max_length\", \"2048\",\n",
    "    \"--train_size\", \"0.9\",\n",
    "    \"--remove_unused_columns\", \"False\",\n",
    "    \"--torch_dtype\", \"bfloat16\",#这里不要float16，会报错\n",
    "    \"--per_device_eval_batch_size\",\"1\",\n",
    "    \"--fp16\",\"False\",\n",
    "]\n",
    "finetune()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PLM_MODEL_PATH = \"Qwen2.5-0.5B\"\n",
    "SFT_MODEL_PATH = \"Finetuned-Qwen2.5-0.5B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有多个GPU，可以修改下面的--hf-num-gpus参数来加速评测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/__init__.py:19: UserWarning: Starting from v0.4.0, all AMOTIC configuration files currently located in `./configs/datasets`, `./configs/models`, and `./configs/summarizers` will be migrated to the `opencompass/configs/` package. Please update your configuration file paths accordingly.\n",
      "  _warn_about_config_migration()\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading mmlu_ppl: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/mmlu/mmlu_ppl.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading hellaswag_clean_ppl: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/hellaswag/hellaswag_clean_ppl.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading winogrande_ll: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/winogrande/winogrande_ll.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading ARC_e_ppl: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/ARC_e/ARC_e_ppl.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading ARC_c_clean_ppl: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/ARC_c/ARC_c_clean_ppl.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading SuperGLUE_BoolQ_few_shot_ppl: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./datasets/SuperGLUE_BoolQ/SuperGLUE_BoolQ_few_shot_ppl.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Loading example: /home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/configs/./summarizers/example.py\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Current exp folder: evals/plm/20241210_132717\n",
      "12/10 13:27:17 - OpenCompass - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - SlurmRunner is not used, so the partition argument is ignored.\n",
      "12/10 13:27:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Partitioned into 1 tasks.\n",
      "12/10 13:27:20 - OpenCompass - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Only use 2 GPUs for total 4 available GPUs in debug mode.\n",
      "12/10 13:27:20 - OpenCompass - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Debug mode, log will be saved to tmp/3403043_debug.log\n",
      "12/10 14:11:15 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - Partitioned into 62 tasks.\n",
      "dataset                                            version    metric                                   mode      Qwen2.5-0.5B_hf\n",
      "-------------------------------------------------  ---------  ---------------------------------------  ------  -----------------\n",
      "lukaemon_mmlu_college_biology                      0eddf6     accuracy                                 ppl                 44.44\n",
      "lukaemon_mmlu_college_chemistry                    9e2300     accuracy                                 ppl                 42.00\n",
      "lukaemon_mmlu_college_computer_science             5a1625     accuracy                                 ppl                 44.00\n",
      "lukaemon_mmlu_college_mathematics                  13e9be     accuracy                                 ppl                 33.00\n",
      "lukaemon_mmlu_college_physics                      f05705     accuracy                                 ppl                 28.43\n",
      "lukaemon_mmlu_electrical_engineering               87e5d9     accuracy                                 ppl                 53.79\n",
      "lukaemon_mmlu_astronomy                            69352a     accuracy                                 ppl                 52.63\n",
      "lukaemon_mmlu_anatomy                              a367fc     accuracy                                 ppl                 42.22\n",
      "lukaemon_mmlu_abstract_algebra                     45f14f     accuracy                                 ppl                 38.00\n",
      "lukaemon_mmlu_machine_learning                     16eb9e     accuracy                                 ppl                 37.50\n",
      "lukaemon_mmlu_clinical_knowledge                   b9517f     accuracy                                 ppl                 55.47\n",
      "lukaemon_mmlu_global_facts                         45ca5d     accuracy                                 ppl                 29.00\n",
      "lukaemon_mmlu_management                           f1f94e     accuracy                                 ppl                 62.14\n",
      "lukaemon_mmlu_nutrition                            e8c66b     accuracy                                 ppl                 58.17\n",
      "lukaemon_mmlu_marketing                            6b54fd     accuracy                                 ppl                 76.07\n",
      "lukaemon_mmlu_professional_accounting              aa502e     accuracy                                 ppl                 39.01\n",
      "lukaemon_mmlu_high_school_geography                c5312c     accuracy                                 ppl                 60.10\n",
      "lukaemon_mmlu_international_law                    c502b5     accuracy                                 ppl                 69.42\n",
      "lukaemon_mmlu_moral_scenarios                      9dab41     accuracy                                 ppl                 24.13\n",
      "lukaemon_mmlu_computer_security                    557e7e     accuracy                                 ppl                 70.00\n",
      "lukaemon_mmlu_high_school_microeconomics           9405bf     accuracy                                 ppl                 50.84\n",
      "lukaemon_mmlu_professional_law                     f36e47     accuracy                                 ppl                 35.85\n",
      "lukaemon_mmlu_medical_genetics                     038ad3     accuracy                                 ppl                 54.00\n",
      "lukaemon_mmlu_professional_psychology              429c8f     accuracy                                 ppl                 45.92\n",
      "lukaemon_mmlu_jurisprudence                        ae7f17     accuracy                                 ppl                 60.19\n",
      "lukaemon_mmlu_world_religions                      904875     accuracy                                 ppl                 59.06\n",
      "lukaemon_mmlu_philosophy                           c9014a     accuracy                                 ppl                 49.84\n",
      "lukaemon_mmlu_virology                             611723     accuracy                                 ppl                 40.96\n",
      "lukaemon_mmlu_high_school_chemistry                a25dca     accuracy                                 ppl                 47.78\n",
      "lukaemon_mmlu_public_relations                     02be4e     accuracy                                 ppl                 49.09\n",
      "lukaemon_mmlu_high_school_macroeconomics           267c80     accuracy                                 ppl                 46.67\n",
      "lukaemon_mmlu_human_sexuality                      9a9941     accuracy                                 ppl                 55.73\n",
      "lukaemon_mmlu_elementary_mathematics               197da6     accuracy                                 ppl                 39.95\n",
      "lukaemon_mmlu_high_school_physics                  777e6e     accuracy                                 ppl                 37.75\n",
      "lukaemon_mmlu_high_school_computer_science         1bae4a     accuracy                                 ppl                 55.00\n",
      "lukaemon_mmlu_high_school_european_history         ad843a     accuracy                                 ppl                 60.61\n",
      "lukaemon_mmlu_business_ethics                      83933d     accuracy                                 ppl                 48.00\n",
      "lukaemon_mmlu_moral_disputes                       2a78ed     accuracy                                 ppl                 52.31\n",
      "lukaemon_mmlu_high_school_statistics               c6e690     accuracy                                 ppl                 41.67\n",
      "lukaemon_mmlu_miscellaneous                        ab0a88     accuracy                                 ppl                 54.79\n",
      "lukaemon_mmlu_formal_logic                         fa56ca     accuracy                                 ppl                 35.71\n",
      "lukaemon_mmlu_high_school_government_and_politics  813526     accuracy                                 ppl                 58.55\n",
      "lukaemon_mmlu_prehistory                           017963     accuracy                                 ppl                 54.94\n",
      "lukaemon_mmlu_security_studies                     d60130     accuracy                                 ppl                 65.31\n",
      "lukaemon_mmlu_high_school_biology                  6f158a     accuracy                                 ppl                 55.16\n",
      "lukaemon_mmlu_logical_fallacies                    03a488     accuracy                                 ppl                 55.21\n",
      "lukaemon_mmlu_high_school_world_history            7d5f06     accuracy                                 ppl                 59.49\n",
      "lukaemon_mmlu_professional_medicine                cdcce1     accuracy                                 ppl                 43.75\n",
      "lukaemon_mmlu_high_school_mathematics              eef511     accuracy                                 ppl                 32.22\n",
      "lukaemon_mmlu_college_medicine                     21a6fb     accuracy                                 ppl                 50.29\n",
      "lukaemon_mmlu_high_school_us_history               e73ee8     accuracy                                 ppl                 54.41\n",
      "lukaemon_mmlu_sociology                            423c74     accuracy                                 ppl                 71.64\n",
      "lukaemon_mmlu_econometrics                         efcf91     accuracy                                 ppl                 29.82\n",
      "lukaemon_mmlu_high_school_psychology               971917     accuracy                                 ppl                 62.94\n",
      "lukaemon_mmlu_human_aging                          406d1b     accuracy                                 ppl                 51.57\n",
      "lukaemon_mmlu_us_foreign_policy                    ac2379     accuracy                                 ppl                 74.00\n",
      "lukaemon_mmlu_conceptual_physics                   7f414f     accuracy                                 ppl                 40.43\n",
      "hellaswag                                          47bff9     accuracy - clean                         ppl                 47.01\n",
      "hellaswag                                          47bff9     accuracy - input contaminated            ppl                 35.71\n",
      "hellaswag                                          47bff9     accuracy - input-and-label contaminated  ppl                 50.91\n",
      "winogrande                                         c5cf57     accuracy                                 ll                  54.30\n",
      "ARC-e                                              a450bd     accuracy                                 ppl                 45.50\n",
      "ARC-c-test                                         a450bd     accuracy - clean                         ppl                 29.00\n",
      "ARC-c-test                                         a450bd     accuracy - input contaminated            ppl                 28.30\n",
      "ARC-c-test                                         a450bd     accuracy - input-and-label contaminated  ppl                 33.45\n",
      "BoolQ                                              8ce714     accuracy                                 ppl                 61.62\n",
      "mmlu-humanities                                    -          naive_average                            ppl                 51.63\n",
      "mmlu-stem                                          -          naive_average                            ppl                 44.00\n",
      "mmlu-social-science                                -          naive_average                            ppl                 55.88\n",
      "mmlu-other                                         -          naive_average                            ppl                 51.02\n",
      "mmlu                                               -          naive_average                            ppl                 49.84\n",
      "mmlu-weighted                                      -          weighted_average                         ppl                 47.86\n",
      "12/10 14:17:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write summary to /home/czc/NLP_project/evals/plm/20241210_132717/summary/summary_20241210_132717.txt\n",
      "12/10 14:17:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write csv to /home/czc/NLP_project/evals/plm/20241210_132717/summary/summary_20241210_132717.csv\n",
      "\n",
      "\n",
      "The markdown format results is as below:\n",
      "\n",
      "| dataset | version | metric | mode | Qwen2.5-0.5B_hf |\n",
      "|----- | ----- | ----- | ----- | -----|\n",
      "| lukaemon_mmlu_college_biology | 0eddf6 | accuracy | ppl | 44.44 |\n",
      "| lukaemon_mmlu_college_chemistry | 9e2300 | accuracy | ppl | 42.00 |\n",
      "| lukaemon_mmlu_college_computer_science | 5a1625 | accuracy | ppl | 44.00 |\n",
      "| lukaemon_mmlu_college_mathematics | 13e9be | accuracy | ppl | 33.00 |\n",
      "| lukaemon_mmlu_college_physics | f05705 | accuracy | ppl | 28.43 |\n",
      "| lukaemon_mmlu_electrical_engineering | 87e5d9 | accuracy | ppl | 53.79 |\n",
      "| lukaemon_mmlu_astronomy | 69352a | accuracy | ppl | 52.63 |\n",
      "| lukaemon_mmlu_anatomy | a367fc | accuracy | ppl | 42.22 |\n",
      "| lukaemon_mmlu_abstract_algebra | 45f14f | accuracy | ppl | 38.00 |\n",
      "| lukaemon_mmlu_machine_learning | 16eb9e | accuracy | ppl | 37.50 |\n",
      "| lukaemon_mmlu_clinical_knowledge | b9517f | accuracy | ppl | 55.47 |\n",
      "| lukaemon_mmlu_global_facts | 45ca5d | accuracy | ppl | 29.00 |\n",
      "| lukaemon_mmlu_management | f1f94e | accuracy | ppl | 62.14 |\n",
      "| lukaemon_mmlu_nutrition | e8c66b | accuracy | ppl | 58.17 |\n",
      "| lukaemon_mmlu_marketing | 6b54fd | accuracy | ppl | 76.07 |\n",
      "| lukaemon_mmlu_professional_accounting | aa502e | accuracy | ppl | 39.01 |\n",
      "| lukaemon_mmlu_high_school_geography | c5312c | accuracy | ppl | 60.10 |\n",
      "| lukaemon_mmlu_international_law | c502b5 | accuracy | ppl | 69.42 |\n",
      "| lukaemon_mmlu_moral_scenarios | 9dab41 | accuracy | ppl | 24.13 |\n",
      "| lukaemon_mmlu_computer_security | 557e7e | accuracy | ppl | 70.00 |\n",
      "| lukaemon_mmlu_high_school_microeconomics | 9405bf | accuracy | ppl | 50.84 |\n",
      "| lukaemon_mmlu_professional_law | f36e47 | accuracy | ppl | 35.85 |\n",
      "| lukaemon_mmlu_medical_genetics | 038ad3 | accuracy | ppl | 54.00 |\n",
      "| lukaemon_mmlu_professional_psychology | 429c8f | accuracy | ppl | 45.92 |\n",
      "| lukaemon_mmlu_jurisprudence | ae7f17 | accuracy | ppl | 60.19 |\n",
      "| lukaemon_mmlu_world_religions | 904875 | accuracy | ppl | 59.06 |\n",
      "| lukaemon_mmlu_philosophy | c9014a | accuracy | ppl | 49.84 |\n",
      "| lukaemon_mmlu_virology | 611723 | accuracy | ppl | 40.96 |\n",
      "| lukaemon_mmlu_high_school_chemistry | a25dca | accuracy | ppl | 47.78 |\n",
      "| lukaemon_mmlu_public_relations | 02be4e | accuracy | ppl | 49.09 |\n",
      "| lukaemon_mmlu_high_school_macroeconomics | 267c80 | accuracy | ppl | 46.67 |\n",
      "| lukaemon_mmlu_human_sexuality | 9a9941 | accuracy | ppl | 55.73 |\n",
      "| lukaemon_mmlu_elementary_mathematics | 197da6 | accuracy | ppl | 39.95 |\n",
      "| lukaemon_mmlu_high_school_physics | 777e6e | accuracy | ppl | 37.75 |\n",
      "| lukaemon_mmlu_high_school_computer_science | 1bae4a | accuracy | ppl | 55.00 |\n",
      "| lukaemon_mmlu_high_school_european_history | ad843a | accuracy | ppl | 60.61 |\n",
      "| lukaemon_mmlu_business_ethics | 83933d | accuracy | ppl | 48.00 |\n",
      "| lukaemon_mmlu_moral_disputes | 2a78ed | accuracy | ppl | 52.31 |\n",
      "| lukaemon_mmlu_high_school_statistics | c6e690 | accuracy | ppl | 41.67 |\n",
      "| lukaemon_mmlu_miscellaneous | ab0a88 | accuracy | ppl | 54.79 |\n",
      "| lukaemon_mmlu_formal_logic | fa56ca | accuracy | ppl | 35.71 |\n",
      "| lukaemon_mmlu_high_school_government_and_politics | 813526 | accuracy | ppl | 58.55 |\n",
      "| lukaemon_mmlu_prehistory | 017963 | accuracy | ppl | 54.94 |\n",
      "| lukaemon_mmlu_security_studies | d60130 | accuracy | ppl | 65.31 |\n",
      "| lukaemon_mmlu_high_school_biology | 6f158a | accuracy | ppl | 55.16 |\n",
      "| lukaemon_mmlu_logical_fallacies | 03a488 | accuracy | ppl | 55.21 |\n",
      "| lukaemon_mmlu_high_school_world_history | 7d5f06 | accuracy | ppl | 59.49 |\n",
      "| lukaemon_mmlu_professional_medicine | cdcce1 | accuracy | ppl | 43.75 |\n",
      "| lukaemon_mmlu_high_school_mathematics | eef511 | accuracy | ppl | 32.22 |\n",
      "| lukaemon_mmlu_college_medicine | 21a6fb | accuracy | ppl | 50.29 |\n",
      "| lukaemon_mmlu_high_school_us_history | e73ee8 | accuracy | ppl | 54.41 |\n",
      "| lukaemon_mmlu_sociology | 423c74 | accuracy | ppl | 71.64 |\n",
      "| lukaemon_mmlu_econometrics | efcf91 | accuracy | ppl | 29.82 |\n",
      "| lukaemon_mmlu_high_school_psychology | 971917 | accuracy | ppl | 62.94 |\n",
      "| lukaemon_mmlu_human_aging | 406d1b | accuracy | ppl | 51.57 |\n",
      "| lukaemon_mmlu_us_foreign_policy | ac2379 | accuracy | ppl | 74.00 |\n",
      "| lukaemon_mmlu_conceptual_physics | 7f414f | accuracy | ppl | 40.43 |\n",
      "| hellaswag | 47bff9 | accuracy - clean | ppl | 47.01 |\n",
      "| hellaswag | 47bff9 | accuracy - input contaminated | ppl | 35.71 |\n",
      "| hellaswag | 47bff9 | accuracy - input-and-label contaminated | ppl | 50.91 |\n",
      "| winogrande | c5cf57 | accuracy | ll | 54.30 |\n",
      "| ARC-e | a450bd | accuracy | ppl | 45.50 |\n",
      "| ARC-c-test | a450bd | accuracy - clean | ppl | 29.00 |\n",
      "| ARC-c-test | a450bd | accuracy - input contaminated | ppl | 28.30 |\n",
      "| ARC-c-test | a450bd | accuracy - input-and-label contaminated | ppl | 33.45 |\n",
      "| BoolQ | 8ce714 | accuracy | ppl | 61.62 |\n",
      "| mmlu-humanities | - | naive_average | ppl | 51.63 |\n",
      "| mmlu-stem | - | naive_average | ppl | 44.00 |\n",
      "| mmlu-social-science | - | naive_average | ppl | 55.88 |\n",
      "| mmlu-other | - | naive_average | ppl | 51.02 |\n",
      "| mmlu | - | naive_average | ppl | 49.84 |\n",
      "| mmlu-weighted | - | weighted_average | ppl | 47.86 |\n",
      "\n",
      "12/10 14:17:17 - OpenCompass - \u001b[4m\u001b[97mINFO\u001b[0m - write markdown summary to /home/czc/NLP_project/evals/plm/20241210_132717/summary/summary_20241210_132717.md\n"
     ]
    }
   ],
   "source": [
    "! opencompass \\\n",
    "    --datasets mmlu_ppl hellaswag_clean_ppl winogrande_ll ARC_e_ppl ARC_c_clean_ppl SuperGLUE_BoolQ_few_shot_ppl \\\n",
    "    --summarizer example \\\n",
    "    --hf-type base \\\n",
    "    --hf-path {PLM_MODEL_PATH} \\\n",
    "    --tokenizer-kwargs padding_side=\"left\" truncation=\"left\" \\\n",
    "    --max-seq-len 2048 \\\n",
    "    --batch-size 2 \\\n",
    "    --hf-num-gpus 2 \\\n",
    "    --work-dir \"evals/plm\" \\\n",
    "    --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/__init__.py:19: UserWarning: Starting from v0.4.0, all AMOTIC configuration files currently located in `./configs/datasets`, `./configs/models`, and `./configs/summarizers` will be migrated to the `opencompass/configs/` package. Please update your configuration file paths accordingly.\n",
      "  _warn_about_config_migration()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/czc/anaconda3/envs/NLP/bin/opencompass\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/cli/main.py\", line 227, in main\n",
      "    cfg = get_config_from_arg(args)\n",
      "  File \"/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/utils/run.py\", line 137, in get_config_from_arg\n",
      "    for dataset in match_cfg_file(datasets_dir, [dataset_name]):\n",
      "  File \"/home/czc/anaconda3/envs/NLP/lib/python3.10/site-packages/opencompass/utils/run.py\", line 70, in match_cfg_file\n",
      "    raise ValueError(err_msg)\n",
      "ValueError: The provided pattern matches 0 or more than one config. Please verify your pattern and try again. You may use tools/list_configs.py to list or locate the configurations.\n",
      "+------------------------+\n",
      "| Not matched patterns   |\n",
      "|------------------------|\n",
      "| alpaca-cleaned         |\n",
      "+------------------------+\n"
     ]
    }
   ],
   "source": [
    "! opencompass \\\n",
    "    --datasets mmlu_ppl hellaswag_clean_ppl winogrande_ll ARC_e_ppl ARC_c_clean_ppl SuperGLUE_BoolQ_few_shot_ppl \\\n",
    "    --summarizer example \\\n",
    "    --hf-type base \\\n",
    "    --hf-path {SFT_MODEL_PATH} \\\n",
    "    --tokenizer-kwargs padding_side=\"left\" truncation=\"left\" \\\n",
    "    --max-seq-len 2048 \\\n",
    "    --batch-size 2 \\\n",
    "    --hf-num-gpus 2 \\\n",
    "    --work-dir \"evals/sft\" \\\n",
    "    --debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4031707/68594135.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(input_ids,dtype=torch.long).to(\"cuda\")\n",
      "/tmp/ipykernel_4031707/68594135.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(attention_mask,dtype=torch.long).to(\"cuda\")\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Both `max_new_tokens` (=2048) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give three tips for staying healthy.\n",
      "1. Exercise regularly: Exercise is an essential part of maintaining good health. Aim to exercise at least 30 minutes a day, five days a week, to help keep your body and mind healthy.\n",
      "\n",
      "2. Eat a balanced diet: A balanced diet is important for maintaining good health. Aim to eat a variety of foods, including fruits, vegetables, whole grains, lean proteins, and healthy fats. Avoid processed foods and sugary drinks.\n",
      "\n",
      "3. Get enough sleep: Getting enough sleep is important for maintaining good health. Aim to get at least 7-8 hours of sleep each night, and try to establish a regular sleep schedule.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"outputs/checkpoint-150\",\n",
    "        torch_dtype=torch.bfloat16 ,\n",
    "    ).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Finetuned-Qwen2.5-0.5B\")\n",
    "input_text = \"Give three tips for staying healthy.\\n\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "attention_mask = tokenizer(input_text, return_tensors=\"pt\").attention_mask\n",
    "input_ids = torch.tensor(input_ids,dtype=torch.long).to(\"cuda\")\n",
    "attention_mask = torch.tensor(attention_mask,dtype=torch.long).to(\"cuda\")\n",
    "output = model.generate(input_ids, attention_mask=attention_mask, max_length=2048)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4061777,
     "sourceId": 7056498,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 164048,
     "modelInstanceId": 141432,
     "sourceId": 166218,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
